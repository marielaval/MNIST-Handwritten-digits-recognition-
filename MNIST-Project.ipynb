{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset - Handwritten Digits Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The objective of this study is to perform image recognition on handwritten digits.**\n",
    "\n",
    "**We will be answering the following questions :**\n",
    "- What is the best performing model ? \n",
    "- Will the models recognize our own hadwriting ? \n",
    "- What is the best model to generate new data ?\n",
    "- Will you be able to distinguish fake from real data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of algorithms that we will compare :**\n",
    "- Linear Classifier \n",
    "- KNN\n",
    "- SVMs\n",
    "- Neural Nets \n",
    "- Convolutional Neural Nets\n",
    "- GAN / VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The MNIST database of handwritten digits has the following characteristics :**\n",
    "- 60,000 training examples \n",
    "- 10,000 testing samples \n",
    "- The size of the images is 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip t*-ubyte.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/victor/Desktop/MNIST-Handwritten-digits-recognition-'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = loadlocal_mnist(\n",
    "        images_path='data/train-images-idx3-ubyte', \n",
    "        labels_path='data/train-labels-idx1-ubyte')\n",
    "\n",
    "X_test, y_test = loadlocal_mnist(images_path = 'data/t10k-images-idx3-ubyte', \n",
    "                                labels_path = 'data/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 60000 x 784\n",
      "\n",
      "1st row [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions: %s x %s' % (X_train.shape[0], X_train.shape[1]))\n",
    "print('\\n1st row', X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image can be coded into a vector of size 28x28 = 784. Each number in the vector represents the corresponding pixel, and takes its value according to the intensity of grey of that pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits:  0 1 2 3 4 5 6 7 8 9\n",
      "labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Class distribution: [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n"
     ]
    }
   ],
   "source": [
    "print('Digits:  0 1 2 3 4 5 6 7 8 9')\n",
    "print('labels: %s' % np.unique(y_train))\n",
    "print('Class distribution: %s' % np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5923., 6742., 5958., 6131., 5842., 5421., 5918., 6265., 5851.,\n",
       "        5949.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store as CSV files\n",
    "np.savetxt(fname='images_train.csv', \n",
    "           X=X_train, delimiter=',', fmt='%d')\n",
    "np.savetxt(fname='labels_train.csv', \n",
    "           X=y_train, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(fname='images_test.csv', \n",
    "           X=X_test, delimiter=',', fmt='%d')\n",
    "np.savetxt(fname='labels_test.csv', \n",
    "           X=y_test, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x113f41048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADqBJREFUeJzt3X+sVHV6x/HPA+xq5Ef8wS0hgr1ItIaIZesEa9ZUKmUFJcGNCS7GlRoiG11NN9lEjU2of2hCalkksaBQEbZsYY27RvyR7rrQSCBKHAxFXOuPGgggcC+6gkRg+fH0j3uwd/HOd8aZM3Pm8rxfyc2dOc985zyOfO6Zme/M+Zq7C0A8A4puAEAxCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAGtXJnw4cP987OzlbuEghlx44dOnDggNVy24bCb2ZTJS2SNFDSv7n7/NTtOzs7VS6XG9klgIRSqVTzbet+2m9mAyX9q6RpksZJmmVm4+q9PwCt1chr/omSPnL3j939j5LWSJqRT1sAmq2R8F8saVev67uzbX/CzOaaWdnMyt3d3Q3sDkCemv5uv7svdfeSu5c6OjqavTsANWok/Hskje51fVS2DUA/0Ej435J0mZmNMbNvS/qBpLX5tAWg2eqe6nP3E2Z2n6TfqGeqb7m7v5tbZwCaqqF5fnd/VdKrOfUCoIX4eC8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBNbRKr5ntkPSFpJOSTrh7KY+m0H8cO3YsWT9+/HjF2saNG5Nj9+zZk6zPnj07WR80qKF/3me9PB6dv3X3AzncD4AW4mk/EFSj4XdJvzWzLWY2N4+GALRGo0/7r3P3PWb2Z5JeM7P/cfcNvW+Q/VGYK0mXXHJJg7sDkJeGjvzuvif73SXpBUkT+7jNUncvuXupo6Ojkd0ByFHd4TezwWY29PRlSd+TtD2vxgA0VyNP+0dIesHMTt/Pf7j7f+bSFYCmqzv87v6xpL/MsRcU4PPPP0/WFyxYkKyvX78+Wd+8efM37qlW1T4HMG/evKbt+2zAVB8QFOEHgiL8QFCEHwiK8ANBEX4gKL7zeBbo7u6uWFu0aFFybLX6kSNHknV3T9bHjBlTsXbRRRclx27ZsiVZf/rpp5P1e+65p2KNT5ty5AfCIvxAUIQfCIrwA0ERfiAowg8ERfiBoJjnbwNHjx5N1h999NFkfcmSJRVrBw8erKunWo0fPz5Zf/311yvWTpw4kRw7YsSIZH3//v3Jeuq/nXl+jvxAWIQfCIrwA0ERfiAowg8ERfiBoAg/EBTz/G1g06ZNyfr8+fNb1MnXjRs3LlnfsGFDsj5s2LCKtU8//bSunpAPjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTVeX4zWy5puqQud78y23ahpF9K6pS0Q9JMd/9D89o8u61YsaJp93355Zcn6zfccEOy/thjjyXrqXn8anbu3Fn3WDSuliP/CklTz9j2kKR17n6ZpHXZdQD9SNXwu/sGSZ+dsXmGpJXZ5ZWSbsm5LwBNVu9r/hHuvje7vE9S+nxLANpOw2/4ec9ibRUXbDOzuWZWNrNyak05AK1Vb/j3m9lIScp+d1W6obsvdfeSu5c4aSLQPuoN/1pJs7PLsyW9mE87AFqlavjNbLWkNyT9hZntNrM5kuZLmmJmH0r6u+w6gH6k6jy/u8+qUJqccy9hLV68OFm/9tprk/WpU8+cif1/1c59P3jw4GS9mbq6Kr5aRAvwCT8gKMIPBEX4gaAIPxAU4QeCIvxAUJy6uw0MHTo0Wb/33ntb1ElrrV+/vugWQuPIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc8f3PPPP5+sHzp0KFnvOYtbZWZWsbZly5bk2GpuvvnmZP3SSy9t6P7Pdhz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo5vn7gePHjyfrn3zyScXavHnzkmNXrVpVV0+nnTp1KlkfMKD+48vo0aOT9WeffbZp+46ARwcIivADQRF+ICjCDwRF+IGgCD8QFOEHgqo6z29myyVNl9Tl7ldm2x6RdLek7uxmD7v7q81qsr87efJksr579+5kfdKkScn6rl27KtbOO++85Nhqc+nTpk1L1levXp2sHz58OFlPOXHiRLL+yiuvJOu33357xdrAgQPr6ulsUsuRf4WkvhaAX+juE7Ifgg/0M1XD7+4bJH3Wgl4AtFAjr/nvM7NtZrbczC7IrSMALVFv+JdIGitpgqS9khZUuqGZzTWzspmVu7u7K90MQIvVFX533+/uJ939lKRlkiYmbrvU3UvuXuro6Ki3TwA5qyv8Zjay19XvS9qeTzsAWqWWqb7VkiZJGm5muyX9k6RJZjZBkkvaIelHTewRQBNUDb+7z+pj8zNN6KXfqjaPv3Xr1mT9mmuuaWj/ixcvrlibPHlycuzYsWOT9SNHjiTr27ZtS9Y3b96crKfs27cvWb/rrruS9dR5+6s95oMGnf2nuuATfkBQhB8IivADQRF+ICjCDwRF+IGgzv75jJykpvMWLVqUHPvAAw80tO/UV1Ml6c4776xYO/fcc5Njv/zyy2R9+vTpyfqbb76ZrJ9zzjkVa48//nhybLUp0mqn7r7++usr1mbOnJkcW+2U50OGDEnWqxk1alRD4/PAkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKeP1NtqeknnniiYu3BBx9Mjh06dGiyvmLFimT9xhtvTNZTc/k7d+5Mjr377ruT9Q0bNiTr48ePT9bXrFlTsXbFFVckxx47dixZv//++5P15cuXV6ytXLkyOfa5555L1qtJfZ1Ykj744IOG7j8PHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjm+TMvv/xysp6ay6/23e6XXnopWb/66quT9ffffz9Zf+qppyrWVq1alRxb7dTcTz75ZLJe7VwDw4YNS9ZTUucCkKSrrroqWU99NuPWW29Njl22bFmyXs3ChQsbGt8KHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IChz9/QNzEZL+rmkEZJc0lJ3X2RmF0r6paROSTskzXT3P6Tuq1QqeblczqHt/FU7j3pquehq58avNo9/8ODBZH379u3JeiOWLFmSrM+ZMydZHzCA40c7KZVKKpfLVstta/k/d0LST919nKS/lvRjMxsn6SFJ69z9MknrsusA+omq4Xf3ve7+dnb5C0nvSbpY0gxJp0+HslLSLc1qEkD+vtFzNjPrlPQdSZsljXD3vVlpn3peFgDoJ2oOv5kNkfQrST9x90O9a97zxkGfbx6Y2VwzK5tZubu7u6FmAeSnpvCb2bfUE/xfuPuvs837zWxkVh8pqauvse6+1N1L7l7q6OjIo2cAOagafjMzSc9Ies/df9artFbS7OzybEkv5t8egGap5Su935X0Q0nvmNnpNZMfljRf0nNmNkfSTknpNY/bXGdnZ7Kemuo7evRocuymTZvqaekrd9xxR7I+ZcqUirVp06Ylx55//vnJOlN5Z6+q4Xf3jZIqzRtOzrcdAK3Cn3UgKMIPBEX4gaAIPxAU4QeCIvxAUJy6O7Nu3bpk/Y033qhYqzaPP3LkyGT9tttuS9arfWV44MCByTrQF478QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU8/yZastBT5o0qa4a0K448gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQVcNvZqPN7L/M7Pdm9q6Z/UO2/REz22NmW7Ofm5rfLoC81HIyjxOSfurub5vZUElbzOy1rLbQ3f+lee0BaJaq4Xf3vZL2Zpe/MLP3JF3c7MYANNc3es1vZp2SviNpc7bpPjPbZmbLzeyCCmPmmlnZzMrd3d0NNQsgPzWH38yGSPqVpJ+4+yFJSySNlTRBPc8MFvQ1zt2XunvJ3UsdHR05tAwgDzWF38y+pZ7g/8Ldfy1J7r7f3U+6+ylJyyRNbF6bAPJWy7v9JukZSe+5+896be+99Oz3JW3Pvz0AzVLLu/3flfRDSe+Y2dZs28OSZpnZBEkuaYekHzWlQwBNUcu7/RslWR+lV/NvB0Cr8Ak/ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUOburduZWbeknb02DZd0oGUNfDPt2lu79iXRW73y7O3P3b2m8+W1NPxf27lZ2d1LhTWQ0K69tWtfEr3Vq6jeeNoPBEX4gaCKDv/Sgvef0q69tWtfEr3Vq5DeCn3ND6A4RR/5ARSkkPCb2VQze9/MPjKzh4rooRIz22Fm72QrD5cL7mW5mXWZ2fZe2y40s9fM7MPsd5/LpBXUW1us3JxYWbrQx67dVrxu+dN+Mxso6QNJUyTtlvSWpFnu/vuWNlKBme2QVHL3wueEzexvJB2W9HN3vzLb9s+SPnP3+dkfzgvc/cE26e0RSYeLXrk5W1BmZO+VpSXdIunvVeBjl+hrpgp43Io48k+U9JG7f+zuf5S0RtKMAvpoe+6+QdJnZ2yeIWlldnmlev7xtFyF3tqCu+9197ezy19IOr2ydKGPXaKvQhQR/osl7ep1fbfaa8lvl/RbM9tiZnOLbqYPI7Jl0yVpn6QRRTbTh6orN7fSGStLt81jV8+K13njDb+vu87d/0rSNEk/zp7etiXvec3WTtM1Na3c3Cp9rCz9lSIfu3pXvM5bEeHfI2l0r+ujsm1twd33ZL+7JL2g9lt9eP/pRVKz310F9/OVdlq5ua+VpdUGj107rXhdRPjfknSZmY0xs29L+oGktQX08TVmNjh7I0ZmNljS99R+qw+vlTQ7uzxb0osF9vIn2mXl5korS6vgx67tVrx295b/SLpJPe/4/6+kfyyihwp9XSrpv7Ofd4vuTdJq9TwNPK6e90bmSLpI0jpJH0r6naQL26i3f5f0jqRt6gnayIJ6u049T+m3Sdqa/dxU9GOX6KuQx41P+AFB8YYfEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg/g9n4oRbuSFGWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show first digit \n",
    "pixels = X_train[5].reshape((28,28))\n",
    "plt.imshow(pixels, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11405b160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = X_train[1].reshape((28,28))\n",
    "plt.imshow(pixels, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11d3d3d30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = X_train[3].reshape((28,28))\n",
    "plt.imshow(pixels, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and Normalizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "Number of images in X_train 60000\n",
      "Number of images in X_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Number of images in X_train', X_train.shape[0])\n",
    "print('Number of images in X_test', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pd.read_csv(\"images_train.csv\")\n",
    "train_labels = pd.read_csv(\"labels_train.csv\")\n",
    "test_images = pd.read_csv(\"images_test.csv\")\n",
    "test_labels = pd.read_csv(\"labels_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-17658d2d832e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\"C\" : [0.1], \"gamma\" : [0.1]}\n",
    "lc = LinearSVC()\n",
    "grid = GridSearchCV(estimator=lc, param_grid=param_grid, scoring='accuracy', cv=2, n_jobs=-1, verbose=1)\n",
    "lc = lc.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.predict(test_images)\n",
    "lc.score(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14ddb8c18>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFj1JREFUeJzt3X/QXmV95/H3RyJVqZogaRYTumG2GVraXRWfASyutWYNgVrDOMjgVM2y7MSdQUd3O1uxnVkslB3dbWv9sWUmI9FgVRpBC3UYMYO/tt3lRwKIQHSJKJIskKcm4g9WLfa7f9xX5DbkSZ5jnnPuJ+T9mrnnPuc61znX98kEPjnnXOc8qSokSZqtp026AEnS4cXgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktRJb8GR5KQkd459vpvkbUmOTbI5yX3te1HrnyTvS7I9yV1JThk71trW/74ka/uqWZJ0cBniyfEkRwE7gdOAi4DdVfWuJBcDi6rq7UnOBt4CnN36vbeqTktyLLAFmAIK2Aq8uKr2zDTecccdV8uXL+/1Z5Kkp5qtW7f+Q1UtPli/BUMUA6wEvl5VDyRZA7y8tW8EvgC8HVgDXFWjJLs5ycIkx7e+m6tqN0CSzcBq4OMzDbZ8+XK2bNnS048iSU9NSR6YTb+h7nGczxP/o19SVQ+15YeBJW15KfDg2D47WttM7ZKkCeg9OJIcDbwa+MS+29rZxZxcK0uyLsmWJFump6fn4pCSpP0Y4ozjLOD2qnqkrT/SLkHRvne19p3ACWP7LWttM7X/jKpaX1VTVTW1ePFBL9FJkn5OQwTH6/jZ+xHXA3tnRq0Frhtrf2ObXXU68Gi7pHUjsCrJojYDa1VrkyRNQK83x5McA7wSeNNY87uATUkuBB4AzmvtNzCaUbUdeAy4AKCqdie5DLit9bt0741ySdLwBpmOO7SpqalyVpUkdZNka1VNHayfT45LkjoxOCRJnRgckqROhnpy/Ij3rUv/5WBj/fJ/+cpgY0k68njGIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE58O66keeGd73znU3KspyLPOCRJnRgckqRODA5JUife49Dgvviy3xpsrN/60hcHG0s6UvR6xpFkYZJrknw1ybYkL0lybJLNSe5r34ta3yR5X5LtSe5KcsrYcda2/vclWdtnzZKkA+v7UtV7gc9U1a8CLwC2ARcDN1XVCuCmtg5wFrCifdYBVwAkORa4BDgNOBW4ZG/YSJKG11twJHku8DLgSoCq+nFVfQdYA2xs3TYC57TlNcBVNXIzsDDJ8cCZwOaq2l1Ve4DNwOq+6pYkHVifZxwnAtPAh5LckeSDSY4BllTVQ63Pw8CStrwUeHBs/x2tbaZ2SdIE9BkcC4BTgCuq6kXAD3jishQAVVVAzcVgSdYl2ZJky/T09FwcUpK0H33OqtoB7KiqW9r6NYyC45Ekx1fVQ+1S1K62fSdwwtj+y1rbTuDl+7R/Yd/Bqmo9sB5gampqTsLoqeiM958xyDh//5a/H2Qc6anoBdfcONhYXz73zM779BYcVfVwkgeTnFRVXwNWAve2z1rgXe37urbL9cCbk1zN6Eb4oy1cbgT+69gN8VXAO7rU8uL/fNWh/0CzsPW/v3GQcaS5tu3yzw0yzq/90SsGGUf96vs5jrcAH01yNHA/cAGjy2ObklwIPACc1/reAJwNbAcea32pqt1JLgNua/0urardPdctSZpBr8FRVXcCU/vZtHI/fQu4aIbjbAA2zG11OtJ94Pf/dpBx3vxnvzvIOJobmz5x6iDjnPfaWwcZpw++ckSS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOun77biSDuDy15872Fh/9FfXDDaWnto845AkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkddJrcCT5ZpKvJLkzyZbWdmySzUnua9+LWnuSvC/J9iR3JTll7DhrW//7kqzts2ZJ0oENccbx21X1wqqaausXAzdV1QrgprYOcBawon3WAVfAKGiAS4DTgFOBS/aGjSRpeJO4VLUG2NiWNwLnjLVfVSM3AwuTHA+cCWyuqt1VtQfYDKweumhJ0kjfwVHAZ5NsTbKutS2pqofa8sPAkra8FHhwbN8drW2m9p+RZF2SLUm2TE9Pz+XPIEka0/fbcV9aVTuT/BKwOclXxzdWVSWpuRioqtYD6wGmpqbm5JiSpCfr9Yyjqna2713Apxjdo3ikXYKife9q3XcCJ4ztvqy1zdQuSZqA3oIjyTFJnr13GVgF3A1cD+ydGbUWuK4tXw+8sc2uOh14tF3SuhFYlWRRuym+qrVJkiagz0tVS4BPJdk7zseq6jNJbgM2JbkQeAA4r/W/ATgb2A48BlwAUFW7k1wG3Nb6XVpVu3usW5J0AL0FR1XdD7xgP+3fBlbup72Ai2Y41gZgw1zXKEnqzifHJUmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1EnvwZHkqCR3JPl0Wz8xyS1Jtif56yRHt/ZfaOvb2/blY8d4R2v/WpIz+65ZkjSzIc443gpsG1t/N/CeqvoVYA9wYWu/ENjT2t/T+pHkZOB84NeB1cBfJjlqgLolSfvRa3AkWQb8DvDBth7gFcA1rctG4Jy2vKat07avbP3XAFdX1Y+q6hvAduDUPuuWJM2s7zOOvwD+APintv484DtV9Xhb3wEsbctLgQcB2vZHW/+ftu9nH0nSwHoLjiSvAnZV1da+xthnvHVJtiTZMj09PcSQknRE6vOM4wzg1Um+CVzN6BLVe4GFSRa0PsuAnW15J3ACQNv+XODb4+372eenqmp9VU1V1dTixYvn/qeRJAGzDI4kN82mbVxVvaOqllXVckY3tz9XVb8HfB44t3VbC1zXlq9v67Ttn6uqau3nt1lXJwIrgFtnU7ckae4tONDGJM8AngUcl2QRkLbpOfz89xneDlyd5E+AO4ArW/uVwEeSbAd2MwobquqeJJuAe4HHgYuq6ic/59iSpEN0wOAA3gS8DXg+sJUnguO7wAdmO0hVfQH4Qlu+n/3MiqqqHwKvnWH/y4HLZzueJKk/BwyOqnov8N4kb6mq9w9UkyRpHjvYGQcAVfX+JL8JLB/fp6qu6qkuSdI8NavgSPIR4F8AdwJ77y8UYHBI0hFmVsEBTAEnt1lOkqQj2Gyf47gb+Gd9FiJJOjzM9ozjOODeJLcCP9rbWFWv7qUqSdK8NdvgeGefRUiSDh+znVX1xb4LkSQdHmY7q+p7jGZRARwNPB34QVU9p6/CJEnz02zPOJ69d3nsd2Sc3ldRkqT5q/PbcWvkbwB/haskHYFme6nqNWOrT2P0XMcPe6lIkjSvzXZW1e+OLT8OfJPR5SpJ0hFmtvc4Lui7EEnS4WG2v8hpWZJPJdnVPtcmWdZ3cZKk+We2N8c/xOg38T2/ff62tUmSjjCzDY7FVfWhqnq8fT4M+Iu9JekINNvg+HaS1yc5qn1eD3y7z8IkSfPTbIPj3wHnAQ8DDwHnAv+2p5okSfPYbKfjXgqsrao9AEmOBf6UUaBIko4gsz3j+Fd7QwOgqnYDL+qnJEnSfDbb4HhakkV7V9oZx2zPViRJTyGzDY4/A/53ksuSXAb8L+C/HWiHJM9IcmuSLye5J8kft/YTk9ySZHuSv05ydGv/hba+vW1fPnasd7T2ryXxHVmSNEGzCo6qugp4DfBI+7ymqj5ykN1+BLyiql4AvBBYneR04N3Ae6rqV4A9wIWt/4XAntb+ntaPJCcD5wO/DqwG/jLJUbP/ESVJc2nWb8etqnur6gPtc+8s+ldVfb+tPr19CngFcE1r3wic05bXtHXa9pVjr3C/uqp+VFXfALYDp862bknS3Or8WvUu2jMfdwK7gM3A14HvVNXjrcsOYGlbXgo8CNC2Pwo8b7x9P/tIkgbWa3BU1U+q6oXAMkZnCb/a11hJ1iXZkmTL9PR0X8NI0hGv1+DYq6q+A3weeAmwMMneGVnLgJ1teSdwAkDb/lxGT6f/tH0/+4yPsb6qpqpqavFi34YiSX3pLTiSLE6ysC0/E3glsI1RgJzbuq0FrmvL17d12vbPVVW19vPbrKsTgRXArX3VLUk6sD6fxTge2NhmQD0N2FRVn05yL3B1kj8B7gCubP2vBD6SZDuwm9FMKqrqniSbgHsZ/RKpi6rqJz3WLUk6gN6Co6ruYj9Pl1fV/exnVlRV/RB47QzHuhy4fK5rlCR1N8g9DknSU4fBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE56C44kJyT5fJJ7k9yT5K2t/dgkm5Pc174XtfYkeV+S7UnuSnLK2LHWtv73JVnbV82SpIPr84zjceD3q+pk4HTgoiQnAxcDN1XVCuCmtg5wFrCifdYBV8AoaIBLgNOAU4FL9oaNJGl4vQVHVT1UVbe35e8B24ClwBpgY+u2ETinLa8BrqqRm4GFSY4HzgQ2V9XuqtoDbAZW91W3JOnABrnHkWQ58CLgFmBJVT3UNj0MLGnLS4EHx3bb0dpmat93jHVJtiTZMj09Paf1S5Ke0HtwJPlF4FrgbVX13fFtVVVAzcU4VbW+qqaqamrx4sVzcUhJ0n70GhxJns4oND5aVZ9szY+0S1C0712tfSdwwtjuy1rbTO2SpAnoc1ZVgCuBbVX152Obrgf2zoxaC1w31v7GNrvqdODRdknrRmBVkkXtpviq1iZJmoAFPR77DOANwFeS3Nna/hB4F7ApyYXAA8B5bdsNwNnAduAx4AKAqtqd5DLgttbv0qra3WPdkqQD6C04qurvgMyweeV++hdw0QzH2gBsmLvqJEk/L58clyR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUie9BUeSDUl2Jbl7rO3YJJuT3Ne+F7X2JHlfku1J7kpyytg+a1v/+5Ks7ateSdLs9HnG8WFg9T5tFwM3VdUK4Ka2DnAWsKJ91gFXwChogEuA04BTgUv2ho0kaTJ6C46q+hKwe5/mNcDGtrwROGes/aoauRlYmOR44Exgc1Xtrqo9wGaeHEaSpAENfY9jSVU91JYfBpa05aXAg2P9drS2mdolSRMysZvjVVVAzdXxkqxLsiXJlunp6bk6rCRpH0MHxyPtEhTte1dr3wmcMNZvWWubqf1Jqmp9VU1V1dTixYvnvHBJ0sjQwXE9sHdm1FrgurH2N7bZVacDj7ZLWjcCq5IsajfFV7U2SdKELOjrwEk+DrwcOC7JDkazo94FbEpyIfAAcF7rfgNwNrAdeAy4AKCqdie5DLit9bu0qva94S5JGlBvwVFVr5th08r99C3gohmOswHYMIelSZIOgU+OS5I6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUyWETHElWJ/laku1JLp50PZJ0pDosgiPJUcD/AM4CTgZel+TkyVYlSUemwyI4gFOB7VV1f1X9GLgaWDPhmiTpiHS4BMdS4MGx9R2tTZI0sFTVpGs4qCTnAqur6t+39TcAp1XVm8f6rAPWtdWTgK8d4rDHAf9wiMeYC/OhjvlQA8yPOqzhCfOhjvlQA8yPOuaihn9eVYsP1mnBIQ4ylJ3ACWPry1rbT1XVemD9XA2YZEtVTc3V8Q7nOuZDDfOlDmuYX3XMhxrmSx1D1nC4XKq6DViR5MQkRwPnA9dPuCZJOiIdFmccVfV4kjcDNwJHARuq6p4JlyVJR6TDIjgAquoG4IYBh5yzy16HaD7UMR9qgPlRhzU8YT7UMR9qgPlRx2A1HBY3xyVJ88fhco9DkjRPGBz7MenXmyTZkGRXkruHHnufOk5I8vkk9ya5J8lbJ1DDM5LcmuTLrYY/HrqGsVqOSnJHkk9PsIZvJvlKkjuTbJlgHQuTXJPkq0m2JXnJwOOf1P4M9n6+m+RtQ9bQ6viP7e/l3Uk+nuQZQ9fQ6nhrq+GeIf4cvFS1j/Z6k/8DvJLRg4a3Aa+rqnsHrOFlwPeBq6rqN4Yadz91HA8cX1W3J3k2sBU4Z+A/iwDHVNX3kzwd+DvgrVV181A1jNXyn4Ap4DlV9aqhx281fBOYqqqJPjOQZCPwP6vqg22m47Oq6jsTquUoRtPzT6uqBwYcdymjv48nV9X/S7IJuKGqPjxUDa2O32D0No1TgR8DnwH+Q1Vt72tMzziebOKvN6mqLwG7hxxzhjoeqqrb2/L3gG0M/MR+jXy/rT69fQb/106SZcDvAB8ceuz5JslzgZcBVwJU1Y8nFRrNSuDrQ4bGmAXAM5MsAJ4F/N8J1PBrwC1V9VhVPQ58EXhNnwMaHE/m6032I8ly4EXALRMY+6gkdwK7gM1VNXgNwF8AfwD80wTGHlfAZ5NsbW9LmIQTgWngQ+3S3QeTHDOhWmD0XNfHhx60qnYCfwp8C3gIeLSqPjt0HcDdwL9O8rwkzwLO5mcfmJ5zBocOKskvAtcCb6uq7w49flX9pKpeyOiNAae2U/PBJHkVsKuqtg457gxeWlWnMHpT9EXtsubQFgCnAFdU1YuAHwAT+VUH7TLZq4FPTGDsRYyuRpwIPB84Jsnrh66jqrYB7wY+y+gy1Z3AT/oc0+B4soO+3uRI0u4rXAt8tKo+Ocla2uWQzwOrBx76DODV7f7C1cArkvzVwDUAP/1XLlW1C/gUo0urQ9sB7Bg787uGUZBMwlnA7VX1yATG/jfAN6pquqr+Efgk8JsTqIOqurKqXlxVLwP2MLpP2xuD48l8vUnTbkxfCWyrqj+fUA2Lkyxsy89kNGnhq0PWUFXvqKplVbWc0d+Hz1XV4P+yTHJMm6RAuzS0itFlikFV1cPAg0lOak0rgcEmTOzjdUzgMlXzLeD0JM9q/62sZHQfcHBJfql9/zKj+xsf63O8w+bJ8aHMh9ebJPk48HLguCQ7gEuq6soha2jOAN4AfKXdYwD4w/YU/1COBza2mTNPAzZV1cSmw07YEuBTo/9HsQD4WFV9ZkK1vAX4aPvH1f3ABUMX0MLzlcCbhh4boKpuSXINcDvwOHAHk3uC/NokzwP+Ebio78kKTseVJHXipSpJUicGhySpE4NDktSJwSFJ6sTgkCR14nRcaSDtAcLvMXqq9/FJ/45q6edlcEjD+u1Jv9lWOlReqpIkdWJwSMOZD2+2lQ6Zl6qk4by0qna29wptTvLV9rtXpMOKZxzSQObJm22lQ2ZwSAOYL2+2leaCl6qkYcynN9tKh8S340qSOvFSlSSpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUif/H2INr/EbrPbyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_labels[\"5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x113a235f8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(test_labels[\"7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'SVM__C':[0.001, 0.1, 100, 10e5], 'SVM__gamma':[10,1,0.1,0.01]} #Decide on the value of C and gamma\n",
    "steps = [('SVM', SVC(kernel='poly'))]\n",
    "pipeline = Pipeline(steps) # define Pipeline object\n",
    "grid = GridSearchCV(pipeline, param_grid=parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "grid.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([60000, 28, 28])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape([10000, 28, 28])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a network with a sequence of two layers. The first dense has 128 nodes and the second dense \n",
    "#is a 10-node softwmax layer : it returns 10 probability scores that sum to 1. They correspond to \n",
    "#the probability that the image belongs to the class. \n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28))\n",
    "])\n",
    "\n",
    "d1 = keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "d_class = keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "model.add(d1)\n",
    "model.add(d_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "model.fit(images_train, labels_train)\n",
    "predictions = model.predict(images_test)\n",
    "#print(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy :\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize the algorithm : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change network depth \n",
    "def create_dense(layer_sizes):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28,28))\n",
    "    ])\n",
    "    \n",
    "    d1 = keras.layers.Dense(layer_sizes[0], activation=tf.nn.relu)\n",
    "    model.add(d1)\n",
    "\n",
    "    for s in layer_sizes[1:]:\n",
    "        d = keras.layers.Dense(units = s, activation = tf.nn.relu)\n",
    "        model.add(d)\n",
    "\n",
    "    d_class = keras.layers.Dense(units=10, activation=tf.nn.softmax)\n",
    "    model.add(d_class)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model \n",
    "def evaluate(model, epochs=5):\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_split=.1, verbose=False)\n",
    "    loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "    \n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in range(1, 5):\n",
    "    model = create_dense([128] * layers)\n",
    "    evaluate(model, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding too many layers overfits the model. The best accuracy is obtained with only one layer in the neural network. With more layers, the neural network fits the training data too precisely, and no longer generalized to data from outside the training set (here, to X_test). Especially with 5 hidden layers we can see that the training accuracy is way larger than the test accuracy, which is an indicator for overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change layer width\n",
    "for nodes in [32, 64, 128, 256, 512, 1024, 2048]:\n",
    "    model = create_dense([nodes])\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More nodes in the hidden layers produce a better performance on the test data. The model reaches the best accuracy with one hidden layer of 2048 nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final model \n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28))\n",
    "])\n",
    "\n",
    "d1 = keras.layers.Dense(2048, activation=tf.nn.relu)\n",
    "d_class = keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "model.add(d1)\n",
    "model.add(d_class)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test accuracy :\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=(5, 5),\n",
    "                 padding='Same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='Same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size=(5, 5),\n",
    "                 padding='Same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size=(3,3),\n",
    "                 padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 86\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction error : 98,5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 222\n",
    "plt.imshow(X_test[image_index].reshape(28, 28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "#import imutils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images_train, labels_train = X_train, y_train \n",
    "\n",
    "images_test, labels_test = X_test, y_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's take 10% of the training data and use that for validation\n",
    "\n",
    "(images_train1, valData, labels_train1, valLabels) = train_test_split(images_train, labels_train,\n",
    "test_size=0.1, random_state=84)\n",
    "\n",
    "# show the sizes of each data split\n",
    "\n",
    "print(\"training data points: {}\".format(len(images_train1)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the values of k for our k-Nearest Neighbor classifier along with the\n",
    "# list of accuracies for each value of k\n",
    "\n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    "\n",
    "# loop over various values of `k` for the k-Nearest Neighbor classifier\n",
    "\n",
    "for k in range(1, 20, 2):\n",
    "          # train the k-Nearest Neighbor classifier with the current value of `k`\n",
    "          model = KNeighborsClassifier(n_neighbors=k)\n",
    "          model.fit(images_train1, labels_train1)\n",
    "          # evaluate the model and update the accuracies list\n",
    "          score = model.score(valData, valLabels)\n",
    "          print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "          accuracies.append(score)\n",
    "        \n",
    "\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(images_train1, labels_train1)\n",
    "          # evaluate the model and update the accuracies list\n",
    "score = model.score(valData, valLabels)\n",
    "print(\"k=%d, accuracy=%.2f%%\" % (1, score * 100))\n",
    "accuracies.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dim = 100\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "\n",
    "\n",
    "def get_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(optimizer):\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(256, input_dim=random_dim,\n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(784, activation='tanh'))\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(optimizer):\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(1024, input_dim=784,\n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(random_dim,))\n",
    "    x=generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan=Model(inputs=gan_input, outputs = gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), figsize=(10,10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples, 28,28)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gan_res/gan_generated_image_epoch_'+str(epoch)+'.png')\n",
    "    #you have to create the repository \"gan_res\" in \"MNIST-Handwritten-digits-recognition-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=1, batch_size=128):\n",
    "    \n",
    "    batch_count = int(X_train.shape[0]/batch_size)\n",
    "    \n",
    "    adam = get_optimizer()\n",
    "    generator = get_generator(adam)\n",
    "    discrimnator = get_discriminator(adam)\n",
    "    gan = get_gan_network(discrimnator, random_dim, generator, adam)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        print('-'*15, 'Epoch %d' %e, '-'*15)\n",
    "        for _ in tqdm_notebook(range(batch_count)):\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
    "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
    "            \n",
    "            generated_images = generator.predict(noise)\n",
    "            X=np.concatenate([image_batch, generated_images])\n",
    "            \n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            \n",
    "            y_dis[:batch_size] = 0.9\n",
    "            \n",
    "            discrimnator.trainable = True\n",
    "            discrimnator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            discrimnator.trainable = False\n",
    "            gan.train_on_batch(noise, y_gen)\n",
    "        plot_generated_images(e, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(20, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input our own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@o.kroeger/tensorflow-mnist-and-your-own-handwritten-digits-4d1cd32bbab4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann Lecun : \"All images are size normalized to fit in a 20x20 pixel box and there are centered in a 28x28 image using the center of mass. These are important information for our preprocessing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the center of mass\n",
    "def getBestShift(img):\n",
    "    cy,cx = ndimage.measurements.center_of_mass(img)\n",
    "\n",
    "    rows,cols = img.shape\n",
    "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "    shifty = np.round(rows/2.0-cy).astype(int)\n",
    "\n",
    "    return shiftx,shifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift the image\n",
    "def shift(img,sx,sy):\n",
    "    rows,cols = img.shape\n",
    "    M = np.float32([[1,0,sx],[0,1,sy]])\n",
    "    shifted = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.zeros((9,784))\n",
    "\n",
    "for i in range(9):\n",
    "    gray = cv2.imread(\"Our_own_images/img\" + str(i) + \".jpeg\", 0)  #Open image\n",
    "    gray = cv2.resize(255-gray, (28, 28)) #Resize image and invert it with a black background\n",
    "    (thresh, gray) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) #Add a treshold to have only black or white in the image, no gray \n",
    "    \n",
    "    #Remove completely black rows and columns at the sides of the image\n",
    "    while np.sum(gray[0]) == 0:\n",
    "        gray = gray[1:]\n",
    "\n",
    "    while np.sum(gray[:,0]) == 0:\n",
    "        gray = np.delete(gray,0,1)\n",
    "\n",
    "    while np.sum(gray[-1]) == 0:\n",
    "        gray = gray[:-1]\n",
    "\n",
    "    while np.sum(gray[:,-1]) == 0:\n",
    "        gray = np.delete(gray,-1,1)\n",
    "\n",
    "    rows,cols = gray.shape\n",
    "    \n",
    "    \n",
    "    #Resize the image so that it fits into a 20x20 box\n",
    "    if rows > cols:\n",
    "        factor = 20.0/rows\n",
    "        rows = 20\n",
    "        cols = int(round(cols*factor))\n",
    "        gray = cv2.resize(gray, (cols,rows))\n",
    "    else:\n",
    "        factor = 20.0/cols\n",
    "        cols = 20\n",
    "        rows = int(round(rows*factor))\n",
    "        gray = cv2.resize(gray, (cols, rows))\n",
    "        \n",
    "        \n",
    "    #Add missing black rows and columns to get a 28x28 image\n",
    "    colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "    rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "    gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
    "    \n",
    "    #Find the center of mass and shift the image in the given directions\n",
    "    shiftx,shifty = getBestShift(gray)\n",
    "    shifted = shift(gray,shiftx,shifty)\n",
    "    gray = shifted\n",
    "\n",
    "    #Divide by 255 to obtain a range from 0 to 1, just like for the images in the MNIST dataset   \n",
    "    flatten = gray.flatten() / 255.0\n",
    "    \n",
    "    images[i] = flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e782c67d4918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#See if our model recognizes our handwriting !\n",
    "model.predict(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
