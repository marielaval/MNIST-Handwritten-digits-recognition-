{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset - Handwritten Digits Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The objective of this study is to perform image recognition on handwritten digits.**\n",
    "\n",
    "**We will be answering the following questions :**\n",
    "- What is the best performing model ? \n",
    "- Will the models recognize our own hadwriting ? \n",
    "- What is the best model to generate new data ?\n",
    "- Will you be able to distinguish fake from real data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of algorithms that we will compare :**\n",
    "- Linear Classifier \n",
    "- KNN\n",
    "- SVMs\n",
    "- Neural Nets \n",
    "- Convolutional Neural Nets\n",
    "- GAN / VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The MNIST database of handwritten digits has the following characteristics :**\n",
    "- 60,000 training examples \n",
    "- 10,000 testing samples \n",
    "- The size of the images is 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip t*-ubyte.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = loadlocal_mnist(\n",
    "        images_path='data/train-images-idx3-ubyte', \n",
    "        labels_path='data/train-labels-idx1-ubyte')\n",
    "\n",
    "X_test, y_test = loadlocal_mnist(images_path = 'data/t10k-images-idx3-ubyte', \n",
    "                                labels_path = 'data/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensions: %s x %s' % (X_train.shape[0], X_train.shape[1]))\n",
    "print('\\n1st row', X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image can be coded into a vector of size 28x28 = 784. Each number in the vector represents the corresponding pixel, and takes its value according to the intensity of grey of that pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Digits:  0 1 2 3 4 5 6 7 8 9')\n",
    "print('labels: %s' % np.unique(y_train))\n",
    "print('Class distribution: %s' % np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store as CSV files\n",
    "np.savetxt(fname='images_train.csv', \n",
    "           X=X_train, delimiter=',', fmt='%d')\n",
    "np.savetxt(fname='labels_train.csv', \n",
    "           X=y_train, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(fname='images_test.csv', \n",
    "           X=X_test, delimiter=',', fmt='%d')\n",
    "np.savetxt(fname='labels_test.csv', \n",
    "           X=y_test, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show first digit \n",
    "pixels = X_train[5].reshape((28,28))\n",
    "plt.imshow(pixels, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = X_train[1].reshape((28,28))\n",
    "plt.imshow(pixels, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = X_train[3].reshape((28,28))\n",
    "plt.imshow(pixels, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and Normalizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d\n",
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Number of images in X_train', X_train.shape[0])\n",
    "print('Number of images in X_test', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pd.read_csv(\"images_train.csv\")\n",
    "train_labels = pd.read_csv(\"labels_train.csv\")\n",
    "test_images = pd.read_csv(\"images_test.csv\")\n",
    "test_labels = pd.read_csv(\"labels_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\" : [0.1], \"gamma\" : [0.1]}\n",
    "lc = LinearSVC()\n",
    "grid = GridSearchCV(estimator=lc, param_grid=param_grid, scoring='accuracy', cv=2, n_jobs=-1, verbose=1)\n",
    "lc = lc.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.predict(test_images)\n",
    "lc.score(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_labels[\"5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(test_labels[\"7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'SVM__C':[0.001, 0.1, 100, 10e5], 'SVM__gamma':[10,1,0.1,0.01]} #Decide on the value of C and gamma\n",
    "steps = [('SVM', SVC(kernel='poly'))]\n",
    "pipeline = Pipeline(steps) # define Pipeline object\n",
    "grid = GridSearchCV(pipeline, param_grid=parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(train_images, train_labels, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([60000, 28, 28])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape([10000, 28, 28])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a network with a sequence of two layers. The first dense has 128 nodes and the second dense \n",
    "#is a 10-node softwmax layer : it returns 10 probability scores that sum to 1. They correspond to \n",
    "#the probability that the image belongs to the class. \n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28))\n",
    "])\n",
    "\n",
    "d1 = keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "d_class = keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "model.add(d1)\n",
    "model.add(d_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "model.fit(images_train, labels_train)\n",
    "predictions = model.predict(images_test)\n",
    "#print(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy :\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize the algorithm : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change network depth \n",
    "def create_dense(layer_sizes):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28,28))\n",
    "    ])\n",
    "    \n",
    "    d1 = keras.layers.Dense(layer_sizes[0], activation=tf.nn.relu)\n",
    "    model.add(d1)\n",
    "\n",
    "    for s in layer_sizes[1:]:\n",
    "        d = keras.layers.Dense(units = s, activation = tf.nn.relu)\n",
    "        model.add(d)\n",
    "\n",
    "    d_class = keras.layers.Dense(units=10, activation=tf.nn.softmax)\n",
    "    model.add(d_class)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model \n",
    "def evaluate(model, epochs=5):\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_split=.1, verbose=False)\n",
    "    loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "    \n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in range(1, 5):\n",
    "    model = create_dense([128] * layers)\n",
    "    evaluate(model, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding too many layers overfits the model. The best accuracy is obtained with only one layer in the neural network. With more layers, the neural network fits the training data too precisely, and no longer generalized to data from outside the training set (here, to X_test). Especially with 5 hidden layers we can see that the training accuracy is way larger than the test accuracy, which is an indicator for overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change layer width\n",
    "for nodes in [32, 64, 128, 256, 512, 1024, 2048]:\n",
    "    model = create_dense([nodes])\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More nodes in the hidden layers produce a better performance on the test data. The model reaches the best accuracy with one hidden layer of 2048 nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final model \n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28))\n",
    "])\n",
    "\n",
    "d1 = keras.layers.Dense(2048, activation=tf.nn.relu)\n",
    "d_class = keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "model.add(d1)\n",
    "model.add(d_class)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test accuracy :\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=(5, 5),\n",
    "                 padding='Same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='Same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size=(5, 5),\n",
    "                 padding='Same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size=(3,3),\n",
    "                 padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 86\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction error : 98,5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 222\n",
    "plt.imshow(X_test[image_index].reshape(28, 28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "#import imutils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images_train, labels_train = X_train, y_train \n",
    "\n",
    "images_test, labels_test = X_test, y_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's take 10% of the training data and use that for validation\n",
    "\n",
    "(images_train1, valData, labels_train1, valLabels) = train_test_split(images_train, labels_train,\n",
    "test_size=0.1, random_state=84)\n",
    "\n",
    "# show the sizes of each data split\n",
    "\n",
    "print(\"training data points: {}\".format(len(images_train1)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the values of k for our k-Nearest Neighbor classifier along with the\n",
    "# list of accuracies for each value of k\n",
    "\n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    "\n",
    "# loop over various values of `k` for the k-Nearest Neighbor classifier\n",
    "\n",
    "for k in range(1, 20, 2):\n",
    "          # train the k-Nearest Neighbor classifier with the current value of `k`\n",
    "          model = KNeighborsClassifier(n_neighbors=k)\n",
    "          model.fit(images_train1, labels_train1)\n",
    "          # evaluate the model and update the accuracies list\n",
    "          score = model.score(valData, valLabels)\n",
    "          print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "          accuracies.append(score)\n",
    "        \n",
    "\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(images_train1, labels_train1)\n",
    "          # evaluate the model and update the accuracies list\n",
    "score = model.score(valData, valLabels)\n",
    "print(\"k=%d, accuracy=%.2f%%\" % (1, score * 100))\n",
    "accuracies.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dim = 100\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "\n",
    "\n",
    "def get_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(optimizer):\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(256, input_dim=random_dim,\n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(784, activation='tanh'))\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(optimizer):\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(1024, input_dim=784,\n",
    "                       kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(random_dim,))\n",
    "    x=generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan=Model(inputs=gan_input, outputs = gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), figsize=(10,10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples, 28,28)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gan_res/gan_generated_image_epoch_'+str(epoch)+'.png')\n",
    "    #you have to create the repository \"gan_res\" in \"MNIST-Handwritten-digits-recognition-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=1, batch_size=128):\n",
    "    \n",
    "    batch_count = int(X_train.shape[0]/batch_size)\n",
    "    \n",
    "    adam = get_optimizer()\n",
    "    generator = get_generator(adam)\n",
    "    discrimnator = get_discriminator(adam)\n",
    "    gan = get_gan_network(discrimnator, random_dim, generator, adam)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        print('-'*15, 'Epoch %d' %e, '-'*15)\n",
    "        for _ in tqdm_notebook(range(batch_count)):\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
    "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
    "            \n",
    "            generated_images = generator.predict(noise)\n",
    "            X=np.concatenate([image_batch, generated_images])\n",
    "            \n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            \n",
    "            y_dis[:batch_size] = 0.9\n",
    "            \n",
    "            discrimnator.trainable = True\n",
    "            discrimnator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            discrimnator.trainable = False\n",
    "            gan.train_on_batch(noise, y_gen)\n",
    "        plot_generated_images(e, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(20, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input our own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@o.kroeger/tensorflow-mnist-and-your-own-handwritten-digits-4d1cd32bbab4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann Lecun : \"All images are size normalized to fit in a 20x20 pixel box and there are centered in a 28x28 image using the center of mass. These are important information for our preprocessing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the center of mass\n",
    "def getBestShift(img):\n",
    "    cy,cx = ndimage.measurements.center_of_mass(img)\n",
    "\n",
    "    rows,cols = img.shape\n",
    "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "    shifty = np.round(rows/2.0-cy).astype(int)\n",
    "\n",
    "    return shiftx,shifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift the image\n",
    "def shift(img,sx,sy):\n",
    "    rows,cols = img.shape\n",
    "    M = np.float32([[1,0,sx],[0,1,sy]])\n",
    "    shifted = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.zeros((9,784))\n",
    "\n",
    "for i in range(9):\n",
    "    gray = cv2.imread(\"Our_own_images/img\" + str(i) + \".jpeg\", 0)  #Open image\n",
    "    gray = cv2.resize(255-gray, (28, 28)) #Resize image and invert it with a black background\n",
    "    (thresh, gray) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) #Add a treshold to have only black or white in the image, no gray \n",
    "    \n",
    "    #Remove completely black rows and columns at the sides of the image\n",
    "    while np.sum(gray[0]) == 0:\n",
    "        gray = gray[1:]\n",
    "\n",
    "    while np.sum(gray[:,0]) == 0:\n",
    "        gray = np.delete(gray,0,1)\n",
    "\n",
    "    while np.sum(gray[-1]) == 0:\n",
    "        gray = gray[:-1]\n",
    "\n",
    "    while np.sum(gray[:,-1]) == 0:\n",
    "        gray = np.delete(gray,-1,1)\n",
    "\n",
    "    rows,cols = gray.shape\n",
    "    \n",
    "    \n",
    "    #Resize the image so that it fits into a 20x20 box\n",
    "    if rows > cols:\n",
    "        factor = 20.0/rows\n",
    "        rows = 20\n",
    "        cols = int(round(cols*factor))\n",
    "        gray = cv2.resize(gray, (cols,rows))\n",
    "    else:\n",
    "        factor = 20.0/cols\n",
    "        cols = 20\n",
    "        rows = int(round(rows*factor))\n",
    "        gray = cv2.resize(gray, (cols, rows))\n",
    "        \n",
    "        \n",
    "    #Add missing black rows and columns to get a 28x28 image\n",
    "    colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "    rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "    gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
    "    \n",
    "    #Find the center of mass and shift the image in the given directions\n",
    "    shiftx,shifty = getBestShift(gray)\n",
    "    shifted = shift(gray,shiftx,shifty)\n",
    "    gray = shifted\n",
    "\n",
    "    #Divide by 255 to obtain a range from 0 to 1, just like for the images in the MNIST dataset   \n",
    "    flatten = gray.flatten() / 255.0\n",
    "    \n",
    "    images[i] = flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e782c67d4918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#See if our model recognizes our handwriting !\n",
    "model.predict(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
